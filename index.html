<!DOCTYPE html>
<html>
<head>
<title>üî• Drake AI - Audio Engine</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<style>
body{
  background:black;
  color:#00ffff;
  font-family:Arial;
  padding:20px;
}

#log{
  height:80vh;
  overflow:auto;
  border:2px solid #00ffff;
  padding:10px;
  font-size:14px;
}

.msg{margin:5px 0;}
.user{color:#00ff88;}
.ai{color:#00ccff;}
.error{color:red;}
</style>
</head>
<body>

<h2>üî• Drake AI ‚Äî WebAudio Always On</h2>

<div id="log"></div>

<script>

const API_KEY = "YOUR_A4F_API_KEY";
let audioContext;
let analyser;
let microphone;
let dataArray;

let wakeDetected = false;
let processing = false;

function log(msg,type="info"){
  const div = document.createElement("div");
  div.className = "msg " + type;
  div.innerText = msg;
  document.getElementById("log").appendChild(div);
  document.getElementById("log").scrollTop =
    document.getElementById("log").scrollHeight;
}

/* ===============================
   START MICROPHONE STREAM
==================================*/

async function startAudioStream(){

  try{

    const stream = await navigator.mediaDevices.getUserMedia({
      audio:true,
      video:false
    });

    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    microphone = audioContext.createMediaStreamSource(stream);
    analyser = audioContext.createAnalyser();

    analyser.fftSize = 512;

    const bufferLength = analyser.frequencyBinCount;
    dataArray = new Uint8Array(bufferLength);

    microphone.connect(analyser);

    log("üé§ Mic Stream Active ‚Äî Monitoring Audio...");

    monitorAudio();

  }catch(err){
    log("‚ùå Mic Access Denied","error");
  }
}

/* ===============================
   CONTINUOUS AUDIO MONITOR
==================================*/

function monitorAudio(){

  analyser.getByteFrequencyData(dataArray);

  let volume = 0;
  for(let i=0;i<dataArray.length;i++){
    volume += dataArray[i];
  }

  volume = volume / dataArray.length;

  // If sound energy is high ‚Üí possible speech
  if(volume > 20){
    detectWakeWord();
  }

  requestAnimationFrame(monitorAudio);
}

/* ===============================
   WAKE WORD DETECTION
==================================*/

async function detectWakeWord(){

  if(processing) return;

  // Convert audio to temporary text using Speech API once
  // (We only use it when sound detected to save power)

  const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
  recognition.lang = "en-US";
  recognition.maxAlternatives = 3;

  recognition.start();

  recognition.onresult = async (event)=>{

    const text = event.results[0][0].transcript.toLowerCase();

    log("üó£ Heard: " + text,"user");

    if(text.includes("drake") || text.includes("drak") || text.includes("draik")){

      log("üî• Wake Word Triggered","ai");

      processing = true;

      speak("Yes boss?");

      setTimeout(()=>{
        listenForCommand();
      },1000);
    }

    recognition.stop();
  };
}

/* ===============================
   LISTEN FOR COMMAND AFTER WAKE
==================================*/

function listenForCommand(){

  const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
  recognition.lang = "en-US";
  recognition.maxAlternatives = 3;

  recognition.start();

  log("üéØ Listening for Command...");

  recognition.onresult = async (event)=>{

    const command = event.results[0][0].transcript.toLowerCase();

    log("üß† Command: " + command,"user");

    if(command.includes("play")){
      const song = command.replace("play","").trim();
      playSong(song);
    }
    else{
      await askAI(command);
    }

    processing = false;
    recognition.stop();
  };
}

/* ===============================
   AI REQUEST
==================================*/

async function askAI(text){

  log("ü§ñ Sending to AI...");

  try{

    const res = await fetch("https://api.a4f.co/v1/chat/completions",{
      method:"POST",
      headers:{
        "Authorization":"Bearer " + API_KEY,
        "Content-Type":"application/json"
      },
      body:JSON.stringify({
        model:"provider-6/gpt-oss-20b",
        messages:[
          {role:"system",content:"You are Drake AI. Reply short."},
          {role:"user",content:text}
        ],
        max_tokens:300,
        temperature:0.7
      })
    });

    const data = await res.json();

    if(!data.choices){
      log("‚ùå API Error: " + JSON.stringify(data),"error");
      return;
    }

    const reply = data.choices[0].message.content;

    log("ü§ñ Drake: " + reply,"ai");
    speak(reply);

  }catch(err){
    log("‚ùå Network Error","error");
  }
}

/* ===============================
   TEXT TO SPEECH
==================================*/

function speak(text){
  const speech = new SpeechSynthesisUtterance(text);
  speech.lang = "en-US";
  speech.rate = 1;
  window.speechSynthesis.speak(speech);
}

/* ===============================
   SONG PLAYER
==================================*/

function playSong(song){

  log("üéµ Playing: " + song);
  speak("Playing " + song);

  const url = "https://www.youtube.com/results?search_query=" +
    encodeURIComponent(song + " official audio");

  window.open(url,"_blank");
}

/* =============================== */

window.onload = startAudioStream;

</script>

</body>
</html>
