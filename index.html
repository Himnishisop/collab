<!DOCTYPE html>
<html>
<head>
<title>üî• Drake AI Ultra</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<style>
body{
    background:#000;
    color:#00ffff;
    font-family:Arial;
    padding:20px;
}

#chat{
    height:60vh;
    overflow-y:auto;
    border:1px solid #00ffff;
    padding:10px;
}

.msg{
    margin:8px 0;
}

.user{color:#00ff88;}
.ai{color:#00ccff;}
.error{color:red;}

#debug{
    margin-top:10px;
    height:20vh;
    overflow-y:auto;
    border:1px solid red;
    padding:5px;
    font-size:12px;
    color:red;
}
</style>
</head>
<body>

<h2>üî• Drake AI Ultra</h2>

<div id="chat"></div>

<h3>üêû Debug</h3>
<div id="debug"></div>

<script>

const API_KEY = "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";
let recognition;
let processing = false;

function log(message,type="debug"){
    const chat = document.getElementById("chat");

    const div = document.createElement("div");
    div.className = "msg " + type;
    div.innerText = message;

    chat.appendChild(div);
    chat.scrollTop = chat.scrollHeight;

    const debug = document.getElementById("debug");
    const time = new Date().toLocaleTimeString();
    debug.innerHTML += `[${time}] ${message}<br>`;
    debug.scrollTop = debug.scrollHeight;
}

function startMic(){

    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = "en-US";
    recognition.continuous = true;
    recognition.interimResults = false;

    recognition.start();
    log("üé§ Listening for wake word 'Drake'...");

    recognition.onresult = async function(event){

        if(processing) return;

        const text = event.results[event.results.length - 1][0].transcript.toLowerCase();
        log("üó£ Heard: " + text,"user");

        if(text.includes("drake")){
            processing = true;

            const command = text.replace("drake","").trim();

            if(command.startsWith("play")){
                playSong(command.replace("play","").trim());
                processing = false;
            } else if(command.length > 0){
                await askAI(command);
                processing = false;
            } else {
                log("‚ùó No command detected","error");
                processing = false;
            }
        }
    };

    recognition.onerror = function(e){
        log("Mic Error: " + e.error,"error");
        recognition.stop();
        setTimeout(()=>recognition.start(),1000);
    };
}

async function askAI(text){

    log("ü§ñ Sending to AI...");

    try{

        const res = await fetch("https://openrouter.ai/api/v1/chat/completions",{
            method:"POST",
            headers:{
                "Authorization":"Bearer " + API_KEY,
                "Content-Type":"application/json"
            },
            body:JSON.stringify({
                model:"liquid/lfm-2.5-1.2b-thinking:free",
                messages:[
                    {role:"system",content:"You are Drake AI. Reply short and natural."},
                    {role:"user",content:text}
                ]
            })
        });

        const data = await res.json();

        if(!data.choices){
            log("‚ùå API Error: " + JSON.stringify(data),"error");
            return;
        }

        const reply = data.choices[0].message.content;

        log("ü§ñ Drake: " + reply,"ai");
        speak(reply);

    }catch(err){
        log("‚ùå Network Error","error");
    }
}

function speak(text){
    const speech = new SpeechSynthesisUtterance(text);
    speech.lang = "en-US";
    window.speechSynthesis.speak(speech);
}

function playSong(song){
    log("üéµ Playing: " + song);
    const url = "https://www.youtube.com/results?search_query=" +
        encodeURIComponent(song + " official audio");
    window.open(url,"_blank");
}

window.onload = startMic;

</script>

</body>
</html>
